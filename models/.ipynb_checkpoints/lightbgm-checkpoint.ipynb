{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d768841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db60d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7faadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBMPipeline:\n",
    "    def __init__(self, n_estimators: int = 100, learning_rate: float = 0.1, \n",
    "                 random_state: int = 42, n_jobs: int = -1, wandb_project: Optional[str] = None, \n",
    "                 wandb_entity: Optional[str] = None, wandb_api_key: Optional[str] = None) -> None:\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        self.model: Optional[lgb.LGBMClassifier] = None\n",
    "        self.wandb_project = wandb_project\n",
    "        self.wandb_entity = wandb_entity\n",
    "\n",
    "        if self.wandb_project and wandb_api_key:\n",
    "            wandb.login(key=wandb_api_key)\n",
    "            wandb.init(project=self.wandb_project, entity=self.wandb_entity, reinit=True)\n",
    "\n",
    "    def load_data(self, data: pd.DataFrame, target_column: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "        data[categorical_columns] = data[categorical_columns].astype(str)\n",
    "        data = pd.get_dummies(data, columns=categorical_columns)\n",
    "        X = data.drop(target_column, axis=1)\n",
    "        y = data[target_column]\n",
    "        return X, y\n",
    "\n",
    "    def split_data(self, X: pd.DataFrame, y: pd.Series, test_size: float = 0.2) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=self.random_state)\n",
    "\n",
    "    def create_model(self) -> None:\n",
    "        self.model = lgb.LGBMClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs\n",
    "        )\n",
    "\n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        if self.model is None:\n",
    "            self.create_model()\n",
    "        \n",
    "        if self.wandb_project:\n",
    "            wandb.config.update({\n",
    "                'n_estimators': self.n_estimators,\n",
    "                'learning_rate': self.learning_rate,\n",
    "                'random_state': self.random_state,\n",
    "                'n_jobs': self.n_jobs\n",
    "            })\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been trained.\")\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if self.wandb_project:\n",
    "            wandb.log({'accuracy': accuracy})\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    def run(self, data: pd.DataFrame, target_column: str) -> float:\n",
    "        X, y = self.load_data(data, target_column)\n",
    "        X_train, X_test, y_train, y_test = self.split_data(X, y)\n",
    "        self.train(X_train, y_train)\n",
    "        accuracy = self.evaluate(X_test, y_test)\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6721870",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lightgbm' has no attribute 'LGBMClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpressure ulcer.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m lgb_pipeline \u001b[38;5;241m=\u001b[39m LightGBMPipeline(\n\u001b[0;32m      4\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     wandb_api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWANDB_API\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mlgb_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaretaker score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 65\u001b[0m, in \u001b[0;36mLightGBMPipeline.run\u001b[1;34m(self, data, target_column)\u001b[0m\n\u001b[0;32m     63\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data(data, target_column)\n\u001b[0;32m     64\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_data(X, y)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mLightGBMPipeline.train\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train: pd\u001b[38;5;241m.\u001b[39mDataFrame, y_train: pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb_project:\n\u001b[0;32m     41\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[0;32m     44\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m     46\u001b[0m         })\n",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m, in \u001b[0;36mLightGBMPipeline.create_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBMClassifier\u001b[49m(\n\u001b[0;32m     30\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m     31\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[0;32m     32\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m     33\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m     34\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lightgbm' has no attribute 'LGBMClassifier'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_excel('pressure ulcer.xlsx')\n",
    "    lgb_pipeline = LightGBMPipeline(\n",
    "        n_estimators=100, \n",
    "        learning_rate=0.1, \n",
    "        random_state=42,\n",
    "        wandb_project='pressure_lightgbm', \n",
    "        wandb_entity=os.getenv('WANDB_ENTITY'),\n",
    "        wandb_api_key=os.getenv('WANDB_API')\n",
    "    )\n",
    "    accuracy = lgb_pipeline.run(data, target_column='caretaker score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8db36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
